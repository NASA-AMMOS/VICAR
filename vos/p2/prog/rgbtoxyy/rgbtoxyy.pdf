process help=*

parm INP	count = 3:10
parm OUT	count = 3:4
parm COLORS	type=integer +
                count = 0:10 +			! special colors
                default = --
parm CONV	type = real +
  		count = 0:10 +
  		default = --
parm IOVF	type = real +
  		count = 0:10 +
  		default = --
parm FILTER	type = integer +
  		count = 0:10 +
  		default = --
parm XYZ	type = real +
  		count = 0:30 +
  		default = --
parm RESPONSE	type = real +
  		count = 0:100 +
  		default = --
parm MODE       type= keyword +
                valid=("RADIANCE","REFLECT") +
                default="RADIANCE"
parm print      type=keyword +
                valid=("PRINT","NOPRINT") +
                default="NOPRINT"
parm project    type=(string,5) +
                valid=("GLL","VGR-1","VGR-2","VIKOR","MAR10","MAR-9", +
                       "WFPC1","WFPC2","NONE","LABEL") +
                default="LABEL"
parm dnscale    type=real +
		count=0:1 +
		default=1.0
end-proc

.title
VICAR2 program "rgbtoxyy"

.help
PURPOSE
"rgbtoxyy" converts images from radiance or I/F units into color space
coordinates. The input images must be registered, at least three in number,
and all from separate spectral bands. Three output real files are
generated, representing: chromaticity x, chromaticity y, and 
tristimulus value Y.

EXECUTION
  The program is executed by specifying up to 10 images
taken through different filters, up to 10 special
colors, and, three output files representing x,y and Y.

OUTPUT FILES:
The first three outputs are in REAL format.

File 1 is chromaticity x (0 to 1).
File 2 is chromaticity y (0 to 1)
File 3 is tristimulus Y  (0 to 100)
 
  The fourth output (optional) contains a chromaticity 2-d histogram.
The file is 256 by 256 byte format on a 100 dn background.
The x chromaticity axis is in the sample direction.
The y chromaticity axis is in the line direction.
Each input dn value in the input pictures
is converted to Yxy and the (x,y) portion is accumulated above the
100 dn gray level as a 2-d histogram. This histogram will reveal the
clustering of colors in the images. 

EXAMPLE
In the following examples the user creates output files, OUT.*, using input
images INP.*, and special colors, 1, 2, and 3.

  VICAR>trucolor INP=(INP.ORA,INP.CLR,INP.GRE) OUT=(x,y,yy) +
  VICAR>+ COLORS=(1,2,3)
 
WRITTEN BY: 		J Lorre 4/1/95

THEORY:
                          Color Calibration

   This document describes the process of color calibration for the
purpose of producing colorimetric products.

   We first address the camera signal (dn) and the computation of U 
and I/F which are the decalibrated camera response. The response (dn) 
of a ccd detector is:

    t*O*a
dn= ----- integral(S*T*F*U*P*dl) + dn0                        (1)
     g*c
 
where:
dn=camera output number
g =gain state ratio factor
t =exposure time (sec)
c =high gain conversion factor (e/pixel/dn)
O =optics solid angle (sr)
a =area of ccd pixel (cm**2/pixel)
S =ccd spectral sensitivity (e/photon)
T =optics spectral transmission
F =filter spectral transmission
U =spectral scene radiance (watts/cm**2/sr/nm)
P =wavelength (nm) /1.9862e-16 (photons/watt-sec)
l =wavelength (nm)
dn0=dark current output number

   We wish to decalibrate this sensor before using the response (dn).
To do this we must extract the radiance U from the integral and solve
for it. The only way to extract U is to assume it is independent of 
wavelength. This is a serious error but one which must be made if
only one filter position is available. Typically we have three or more
filters if we are to perform color reconstruction, but for now we will
ignore this problem.

   Solving (1) for U we have:

      (dn-dn0)*g*c
U=-------------------------         watts/cm**2/sr/nm         (2)
  t*O*a*integral(S*T*F*P*dl)

or, in terms of reflectance I/F we have:

      (dn-dn0)*g*c*pi
I/F=-----------------------------     dimensionless albedo     (3)
     t*O*a*integral(S*T*F*H*P*dl)

where H is the solar irradiance incident on the surface.

To simplify things we denote from now on in the text both U
and I/F as symbol Q. In general U is used to produce color
for an additive device like a color TV monitor and I/F is used
for a subtractive device like a film recorder. 

We adopt a set of i special colors with known spectra C(i).
These spectra represent colors which we intend the camera to
reproduce with some precision. For example Kodak uses sky blue,
white cloud, green grass, and skin color as it's four special
colors for film process control. We could use Jupiter 
characteristic spectra.
The tristimulus values of these colors are computed from:

X(i)=integral(C(i)*x*dl)
Y(i)=integral(C(i)*y*dl)     1<=i<=I                           (4)
Z(i)=integral(C(i)*z*dl)

where: x,y,z are the standard CIE color matching functions.

We expose the camera to each of the colors to record the Q(ij) 
responses given by equation(2 or 3) in each of J filter positions.

Because the form of equations (1) and (4) are similar and linear it
is possible to represent the tristimulus values as a linear
combination of the camera responses Q(ij) to each special color i
in filter position j:

X(i)=A1*Q(i1)+A2*Q(i2)+A3*Q(i3)...AJ*Q(iJ)    
Y(i)=B1*Q(i1)+B2*Q(i2)+B3*Q(i3)...BJ*Q(iJ)   1<=i<=I        (5)
Z(i)=C1*Q(i1)+C2*Q(i2)+C3*Q(i3)...CJ*Q(iJ)    

There are as many X equations as there are special colors and as many
A terms as filters. We can solve for the A,B,C coefficients from each
group of the above equations. For input Q(ij) values taken through the
same filters used to solve equations (5) we can compute the tristimulus
values X,Y,Z. These are the values the eye should see.


To create a color product from a set of J input filters we do:

First:
1. Select a set of I representative special colors for which
   camera responses are known (from equations 2 or 3) and
   tristimulus values are known (from equation 4).
2. Solve equation (5) for the 3*J coefficients A(j),B(j),C(j).

Then, for each pixel:
3. From equation (5) compute the X,Y,Z tristimulus values.
4. Convert from tristimulus to chromaticity.
      x=X/(X+Y+Z) and y=Y/(X+Y+Z)



   Discussion

   We must present an argument for the validity of using U or I/F
since we have approximated these functions as independent of
wavelength. Equation (5) is justified because it is a linear
representation of responses which are themselves linear integrals.
Any approximation which is linear such as substituting a flat
function for the scene radiance can be compensated for by the
three sets of least squares fit coefficients A,B, and C.
The important criterion is that I/F be a measurable quantity.
Since dn is proportional with exposure and I/F is proportional
with dn then I/F is measurable and correlatable to X,Y, and Z.
Precisely the same method is used in determining chemical
abundances from spectra such as in NIMS. Equation (5) locks
the camera response to XYZ for the colors of interest.
   One way to get into trouble with equation (5) is to include
filter positions which fall partially out of the spectral
band of the color matching functions x,y,z. Any IR filter would
cause this problem. Another way is to include filters which 
overlap so much spectrally that the images they produce are
nearly identical. Both these cases can be mitigated to some
extent by using the first three terms in the principal 
component transformation of the input images. We must use the
same rotation matrix obtained from the special colors to rotate
the images of unknown scenes. 
   Equation (5) provides a least squares fit between 
the U or I/F values and tristimulus values, both obtained from
special color targets. Later on these same A,B,C coefficients
will be used to convert from U or I/F to tristimulus values for
each pixel in the image. It is imperative that identical
means be used to compute U or I/F (Q) in both cases. Thus the
cameras must be exposed to each of the special colors rather than
U or I/F being computed theoretically. The point is that both U
and I/F are wrong ! They are wrong because of the limitations imposed
by broad band radiometry. To get consistent results we must make the
same error at both the calibration and the evaluation ends.
   One can compute the I/F values theoretically for the special
colors instead of exposing the camera to them. As discussed this
is not correct but, for the sake of completeness, we present
the formula:

      integral(S*T*F*U*dl)
I/F =-------------------------
      integral(S*T*F*H*dl)

where H= The incident spectral irradiance to a surface.
      U= The reflected spectral radiance from the surface.
      U= H*R/pi, where R= The spectral reflectance of the surface.

   Alternative color method.

   There is an alternative method to color reconstruction.
This is to estimate the true spectral distribution of U or
I/F from a synthesis of the U or I/F values obtained through a
set of different camera filters (the very case we have). In this
scenario we attempt to guess the spectral radiance U which 
solves equation (1) for the J dn values AT EACH PIXEL.
Then we can integrate this function using equation (6) to
achieve the tristimulus values at each pixel directly
without using equation (5). This has been done by
Steve Wall JGR,Vol 8,No 28,pp 4401-4411. In this case special
colors are used more as a means of refining the method of
estimating U (since it is known) and of verifying results.

   Required calibration data:

1. Special colors targets imaged by the camera.
   This includes knowledge of the illuminant and target reflectance
   or transmittance curves, and the camera I/F or U responses.

2. A matrix spanning all dn ranges for calibrating the film recorder
   and TV monitor. This includes computations of the tristimulus
   values at each matrix point. A 5 by 5 by 5 cube would be adequate.



.level1

.vari INP
input image files

.vari OUT
output image files

.vari COLORS
special colors

.vari CONV
input image conversion factors
for radiance.

.vari IOVF
input image conversion factors
for reflectance.

.vari FILTER
GLL filter positions.

.vari XYZ
Tristimulus values
for special colors

.vari RESPONSE
The radiance or reflectance 
for special colors

.vari MODE
reflectance or radiance

.vari PRINT
print least squares fit

.vari PROJECT
override project type

.vari dnscale
multiply the input
dn's by dnscale

.level2
.vari INP
INP = (input1,...,inputN), where the inputs are up to ten 
images decalibrated by the program GALSOS.  The images must have been taken
with different filters, must all be the same size, and registered.

.vari OUT
OUT = (x chromaticity, y chromaticity, Y tristimulus), optional_2d_histogram
Outputs 1-3 are always REAL format.
There is an optional fourth BYTE output file containing a 2-d histogram of
the chromaticity space. See help file for specifics.

.vari COLORS
COLORS = (1,...,10), where the colors are up to 10 special 
colors.  There must be at least as many colors named as there are input images.
Three valid colors have been defined for GLL, they have the names:
NAME     number       description                 comments
desert     1       Earth desert yellow  
water      2       Earth ocean blue     
cloud      3       Earth clouds         
Tables of XYZ tristimulus values and response in both radiance and
reflectance for these 3 colors are built into the program already.
If you specify the XYZ and RADIANCE values by parameter input then
you need not specify special colors.
Example: colors=(1,2,3)

.vari CONV
CONV=(factor1,...,factorN), where each conversion factor corresponds to an 
input image (as they are ordered in INP).  CONV allows all input images to be
scaled in the same units, and should be the same as those specified in the
program GALSOS.  Each factor is multiplied by each pixel in the corresponding 
input image.  The number of factors specified must be at most equal to the 
number of inputs specified.
The default is to use CONV values in the picture labels.
Only used in the 'RADIANCE mode.

.vari IOVF
IOVF=(factor1,...,factorN), where each conversion factor corresponds to an 
input image (as they are ordered in INP).  IOVF allows all input images to be
scaled in the same units, and should be the same as those specified in the
program GALSOS.  Each factor is multiplied by each pixel in the corresponding 
input image.  The number of factors specified must be at most equal to the 
number of inputs specified.
The default is to use IOVF values in the picture labels.
Only used in the 'REFLECT mode.

.vari FILTER
The GLL filter position numbers (0 to 7) for each of the input images
in the order of input. Defaults to the filter position in the image
label.

.vari XYZ
Tristimulus values in the order X, Y, Z for each special color.
These offer a manual input. Usually they come from internal
tables pointed to by the COLORS keyword.

.vari RESPONSE
The radiance or reflectance values for each special color and for
each filter position input. In the order of each input for the
first special color followed by the order of input for the second
color...
These offer a manual input. Usually they come from internal
tables pointed to by the COLORS keyword and the FILTER keyword.
The I/F and CONV values are included in the RESPONSE so you must
provide either I/F*dn or CONV*dn.

.vari MODE
Specifies either reflectance or radiance units are to be used.
Specify either: 'RADIANCE or 'REFLECT (default is radiance).
Decalibrated images come with both I/F and CONV values so you must
tell the program which to use.

.vari PRINT
print least squares fit coefficients and coefficient residuals.

.vari PROJECT
Determines how to read the label to get information.

If you want to override project type in picture label and force the program 
to read that type of label then you can specify one of:
 GLL VGR-1 VGR-2 VIKOR MAR10 MAR-9 WFPC1 WFPC2

To not read any label specity : NONE

To let the program decide, specify: LABEL ( this is the default)

.vari dnscale
multiply the input dn's by dnscale. Used to rescale images compressed to byte 
format in order to restore the units to radiance or to reflectance.
 Defaults to 1.

.end
