#!/usr/bin/env python3

# This script reads in an AUGMENTED tiepoints file and returns all tiepoint
# information as a Pandas dataframe. These are the tiepoints files generated
# by marsnav2 which include information on before/after XYZ points, NOT those
# generated by tiepointing methods such as 'marsautotie2'. The purpose of 
# generating dataframes is to perform statistical analyses to test and debug
# bundle adjustment methods, such as 'marsnav2'. This can only be done 
# properly if ALL information related to each tiepoint, including before/
# after residuals, XYZ, and miss distances are available, such that outliers 
# can be detected. The respective filenames for these end with '_final.tpt'. 
#
#
# Sample data:
#
"""
    <tie type="0" left_key="0" right_key="1">
      <left      line="641.538696" samp="735.450867"/>
      <projected line="727.857544" samp="952.837036"/>
      <right     line="727.857544" samp="952.837036"/>
      <left_init_residual     line="-3.379146" samp="4.465482"/>
      <left_final_residual    line="-3.825021" samp="4.665039"/>
      <right_init_residual    line="1.616774" samp="-5.342157"/>
      <right_final_residual   line="0.433895" samp="-0.838790"/>
      <init_miss dist="0.000000"/>
      <final_miss dist="0.000000"/>
      <init_xyz x="-14.445865" y="-11.106664" z="1.501687"/>
      <final_xyz x="-14.445821" y="-11.106483" z="1.501683"/>
      <track  id="1"/>
      <flags quality="0.000000" interactive="0"/>
"""
# ==============================================================================

import os
import sys
import argparse
import numpy as np
import pandas as pd
import re  # regular expressions

# ==============================================================================

# Main script:

# Use Python's 'argparser':
parser = argparse.ArgumentParser()
parser.add_argument("input_tiepoints", help="Input tiepoints file location")
parser.add_argument("first_image_index", help="Index of the first image in the \
	batch (first image in the scene has index = 0)")
parser.add_argument("-v", "--verbose", action="store_true", help="Print verbose script output")
args = parser.parse_args()
verbose = args.verbose

if verbose:
	print('\n-----SLAM_TIE_DATAFRAME.PY-----\n')
	print('Input tiepoints file location: ', args.input_tiepoints)
	print('Index of the first image in the current batch: ', \
		  args.first_image_index)

inputfile = open(str(args.input_tiepoints), "rt") 
contents = inputfile.readlines()  
inputfile.close()

# To keep indexing consistent across batches, we need to track the index 
# (0-based) of the first absolute image of this batch. It should be a 
# multiple of the sliding windows size minus the overlap:

first_image_index = int(args.first_image_index)

if verbose:
	print('Index of the first image in the current batch: ', first_image_index)

# Parse all lines related to a given tiepoint:

alldata = []

for count, line in enumerate(contents):

	if "<tie type=" in line:

		#print(count, line)		
		# Extract the tiepoint type, left key, and right key:
		digits = np.array([int(s) for s in line.split('"') if s.isdigit()])
		digits = np.add(digits, np.array([0, first_image_index, \
					    first_image_index]))
		#print(digits)
		# Extract the left pixel position:
		nextline = contents[count+1]
		left = np.array(re.findall("[+-]?\d+\.\d+", nextline)).astype(float)
		#print(left)
		# Projected pixel position:
		nextline = contents[count+2]
		projected = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(projected)
		# Right pixel position:
		nextline = contents[count+3]
		right = np.array(re.findall("[+-]?\d+\.\d+", nextline)).astype(float)
		#print(right)
		# Left_init_residual:
		nextline = contents[count+4]
		left_init_residual = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(left_init_residual)
		# Left_final_residual:
		nextline = contents[count+5]
		left_final_residual = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(left_final_residual)
		# Right_init_residual:
		nextline = contents[count+6]
		right_init_residual = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(right_init_residual)
		# Right_final_residual:
		nextline = contents[count+7]
		right_final_residual = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(right_final_residual)
		# Init_miss dist:
		nextline = contents[count+8]
		init_miss_dist = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(init_miss_dist)
		# Final_miss dist:
		nextline = contents[count+9]
		final_miss_dist = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(final_miss_dist)
		# Init_xyz:
		nextline = contents[count+10]
		init_xyz = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(init_xyz)
		# Final_xyz:
		nextline = contents[count+11]
		final_xyz = np.array(re.findall("[+-]?\d+\.\d+", \
							 nextline)).astype(float)
		#print(final_xyz)
		# Track  id:
		nextline = contents[count+12]
		track_id = np.array([int(s) for s in nextline.split('"') \
							 if s.isdigit()])
		#print(track_id)
		
		# Append all data to a numpy array. Use a list comprehension to 
		# concatenate all values in each variable, and then append to the
		# total list. The inline loop is equivalent to a nested for loop:

		current_line = [j for i in [digits, left, projected, right, \
						 left_init_residual, left_final_residual, \
						 right_init_residual, right_final_residual, \
						 init_miss_dist, final_miss_dist, init_xyz, \
						 final_xyz, track_id] for j in i] 
		alldata.append(current_line)

# Create a Pandas dataframe from the complete table, and save to CSV:

df = pd.DataFrame(alldata, columns=['type', 'left_key', 'right_key', \
		 'left_line', 'left_samp', 'projected_line', 'projected_samp', \
		 'right_line', 'right_samp', 'left_init_residual_line', \
		 'left_init_residual_samp', 'left_final_residual_line', \
		 'left_final_residual_samp', 'right_init_residual_line', \
		 'right_init_residual_samp', 'right_final_residual_line', \
		 'right_final_residual_samp', 'init_miss_dist', 'final_miss_dist', \
		 'init_xyz_x', 'init_xyz_y', 'init_xyz_z', 'final_xyz_x', \
		 'final_xyz_y', 'final_xyz_z', 'track_id'])

if verbose:
	print('Final dataframe: ', df)

# Save to the same location and filename, but change the extension:

outfile = os.path.splitext(str(sys.argv[1]))[0]+'.csv'  
df.to_csv(outfile)

